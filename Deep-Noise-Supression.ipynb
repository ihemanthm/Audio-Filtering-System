{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbfr5h0ndhWZSPFZ9WHp8X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4HpeQ3kIcyj","executionInfo":{"status":"ok","timestamp":1744997141151,"user_tz":-330,"elapsed":42,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}},"outputId":"ccbfe6a4-9d6d-4526-9d88-0f1971b5a84e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":119}],"source":["# Check for the availability of GPU\n","import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","source":["# !pip install torch torchaudio librosa soundfile numpy pesq sounddevice scipy"],"metadata":{"id":"TLq40bm5lcFM","executionInfo":{"status":"ok","timestamp":1744997145307,"user_tz":-330,"elapsed":5,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["# !pip install pesq"],"metadata":{"id":"gKHAWEF1e_Rm","executionInfo":{"status":"ok","timestamp":1745033227658,"user_tz":-330,"elapsed":51,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","import soundfile as sf\n","import random\n","from glob import glob\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from pesq import pesq\n","from scipy.io import wavfile"],"metadata":{"id":"lgS-1vlBXGyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"zsXXnUXeJHc_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744997145242,"user_tz":-330,"elapsed":4095,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}},"outputId":"0656b672-5024-49a3-8a3b-19262ea5405e"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["clips_path = os.path.join('/content/drive/MyDrive/DNS', 'clips')\n","noise_path = os.path.join('/content/drive/MyDrive/DNS', 'noise')\n","output_path = os.path.join('/content/drive/MyDrive/DNS', 'output')"],"metadata":{"id":"NCgHKzJAlEdQ","executionInfo":{"status":"ok","timestamp":1745033286014,"user_tz":-330,"elapsed":26,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["clean_files = [os.path.join(clips_path,f) for f in os.listdir(clips_path) if os.path.isfile(os.path.join(clips_path, f))]\n","clean_files.sort()\n","noisy_files = [os.path.join(noise_path,f) for f in os.listdir(noise_path) if os.path.isfile(os.path.join(noise_path, f))]\n","noisy_files.sort()\n","\n","# Ensure clean_files and noisy_files have the same length\n","min_len = min(len(clean_files), len(noisy_files))\n","clean_files = clean_files[:min_len]\n","noisy_files = noisy_files[:min_len]\n","\n","print(len(clean_files), len(noisy_files))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMB84-uTmv2c","executionInfo":{"status":"ok","timestamp":1744997145298,"user_tz":-330,"elapsed":32,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}},"outputId":"89d368f3-77e9-43e8-fd34-d8c15af798d0"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["915 915\n"]}]},{"cell_type":"code","source":["# pre process the data, combining clear_voice and noise for training\n","def load_audio(file_path, sr=16000):\n","  try:\n","    audio, _ = librosa.load(file_path, sr=sr, mono=True)\n","    return audio\n","  except Exception as e:\n","    print(f\"Error loading audio file {file_path}: {e}\")\n","    return None\n","\n","def normalize_audio(y):\n","  if y is None or len(y) == 0:\n","    return y\n","  return y / np.max(np.abs(y))\n","\n","def mix_audio(speech, noise, snr_db):\n","  \"\"\"\n","  Mixes speech with noise at given SNR (Signal-to-Noise Ratio)\n","  \"\"\"\n","  if speech is None or noise is None:\n","    return None\n","  speech_power = np.mean(speech ** 2)\n","  noise_power = np.mean(noise ** 2)\n","\n","  # Avoid division by zero\n","  if noise_power == 0:\n","    noise_power = 1e-10\n","\n","  target_noise_power = speech_power / (10 ** (snr_db / 10))\n","  noise = noise * np.sqrt(target_noise_power / noise_power)\n","  mixed = speech + noise\n","  return normalize_audio(mixed)\n","\n","def extract_mfcc(y, sr=16000, n_mfcc=40):\n","  if y is None:\n","    return None\n","  mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n","  return mfcc.T\n","\n","def process_pair(speech_path, noise_path, output_dir, snr_db=5):\n","  speech = load_audio(speech_path)\n","  noise = load_audio(noise_path)\n","\n","  if speech is None or noise is None:\n","    print(f\"Skipping pair due to audio loading error: {speech_path}, {noise_path}\")\n","    return None, None\n","\n","  # Trim noise to speech length or pad speech with silence\n","  if len(noise) < len(speech):\n","      noise = np.tile(noise, int(np.ceil(len(speech) / len(noise))))\n","  elif len(noise) > len(speech):\n","      speech = np.pad(speech, (0, len(noise) - len(speech)), 'constant')\n","\n","  noise = noise[:len(speech)]\n","  mixed = mix_audio(speech, noise, snr_db)\n","\n","  base_name = os.path.basename(speech_path).replace('.mp3', '.wav')\n","  try:\n","      sf.write(os.path.join(output_dir, f'clean_{base_name}'), speech, 16000)\n","      sf.write(os.path.join(output_dir, f'noisy_{base_name}'), mixed, 16000)\n","  except Exception as e:\n","      print(f\"Error writing audio files: {e}\")\n","      return None, None\n","\n","  return speech, mixed\n","\n","def preprocess_dataset(speech_folder, noise_folder, output_dir, sample_count=1000):\n","  speech_files = glob(os.path.join(speech_folder, '*.mp3'))\n","  noise_files = glob(os.path.join(noise_folder, '**/*.wav'), recursive=True)\n","\n","  os.makedirs(output_dir, exist_ok=True)\n","\n","  for i in range(sample_count):\n","      if not speech_files or not noise_files:\n","          print(\"No speech or noise files found. Exiting.\")\n","          break\n","\n","      s_path = random.choice(speech_files)\n","      n_path = random.choice(noise_files)\n","      process_pair(s_path, n_path, output_dir)\n","\n","if __name__ == \"__main__\":\n","  preprocess_dataset(\n","      speech_folder=clips_path,\n","      noise_folder=noise_path,\n","      output_dir=output_path,\n","      sample_count=10\n","  )"],"metadata":{"id":"bD7QXPjmXcs9","executionInfo":{"status":"ok","timestamp":1744997151475,"user_tz":-330,"elapsed":6130,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["class AudioDataset(Dataset):\n","    def __init__(self, clean_files, noisy_files, sr=16000, n_mfcc=40, seq_len=256):\n","        self.clean_files = clean_files\n","        self.noisy_files = noisy_files\n","        self.sr = sr\n","        self.n_mfcc = n_mfcc\n","        self.seq_len = seq_len\n","\n","    def __len__(self):\n","        return min(len(self.clean_files), len(self.noisy_files))\n","\n","    def __getitem__(self, idx):\n","        try:\n","            clean_path = self.clean_files[idx]\n","            noisy_path = self.noisy_files[idx]\n","\n","            clean, _ = librosa.load(clean_path, sr=self.sr)\n","            noisy, _ = librosa.load(noisy_path, sr=self.sr)\n","\n","            # Ensure both clean and noisy audio have the same length\n","            min_len = min(len(clean), len(noisy))\n","            clean = clean[:min_len]\n","            noisy = noisy[:min_len]\n","\n","            clean_mfcc = librosa.feature.mfcc(y=clean, sr=self.sr, n_mfcc=self.n_mfcc)\n","            noisy_mfcc = librosa.feature.mfcc(y=noisy, sr=self.sr, n_mfcc=self.n_mfcc)\n","\n","             # Pad or truncate to the fixed sequence length\n","            if clean_mfcc.shape[1] < self.seq_len:\n","                clean_mfcc = np.pad(clean_mfcc, ((0, 0), (0, self.seq_len - clean_mfcc.shape[1])), mode='constant')\n","            else:\n","                clean_mfcc = clean_mfcc[:, :self.seq_len]\n","\n","            if noisy_mfcc.shape[1] < self.seq_len:\n","                noisy_mfcc = np.pad(noisy_mfcc, ((0, 0), (0, self.seq_len - noisy_mfcc.shape[1])), mode='constant')\n","            else:\n","                noisy_mfcc = noisy_mfcc[:, :self.seq_len]\n","\n","            return torch.tensor(noisy_mfcc).unsqueeze(0).float(), torch.tensor(clean_mfcc).unsqueeze(0).float()\n","\n","        except Exception as e:\n","            print(f\"Error processing item {idx}: {e}\")\n","            # Return empty tensors with the expected shape in case of error\n","            return torch.empty(1, self.n_mfcc, self.seq_len), torch.empty(1, self.n_mfcc, self.seq_len)"],"metadata":{"id":"holrL1PjmE-k","executionInfo":{"status":"ok","timestamp":1744997151501,"user_tz":-330,"elapsed":8,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class CNNDenoiser(nn.Module):\n","    def __init__(self):\n","        super(CNNDenoiser, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU()\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"metadata":{"id":"IxUOt5W5pZ90","executionInfo":{"status":"ok","timestamp":1744997151525,"user_tz":-330,"elapsed":21,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["# --- Config ---\n","EPOCHS = 10\n","BATCH_SIZE = 8\n","DATA_DIR = output_path  # Assuming output_path is defined elsewhere\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# --- Dataset & Loader ---\n","# Assuming clean_files and noisy_files are defined elsewhere\n","dataset = AudioDataset(clean_files, noisy_files)\n","loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","\n","# --- Model, Loss, Optimizer ---\n","model = CNNDenoiser().to(DEVICE)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# --- Training Loop ---\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    for i, (noisy, clean) in enumerate(loader):\n","        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        output = model(noisy)\n","\n","        # Ensure shapes match before calculating loss\n","        if output.shape != clean.shape:\n","            min_time_dim = min(output.shape[-1], clean.shape[-1])  # Assuming time dimension is the last\n","            output = output[:, :, :, :min_time_dim]\n","            clean = clean[:, :, :, :min_time_dim]\n","\n","        loss = criterion(output, clean)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"[Epoch {epoch + 1}/{EPOCHS}] Loss: {total_loss / (i + 1):.4f}\")  # Average loss per batch\n","\n","# --- Save the model ---\n","torch.save(model.state_dict(), \"cnn_denoiser.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ap-h_D_rdj-7","executionInfo":{"status":"ok","timestamp":1744997486348,"user_tz":-330,"elapsed":334817,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}},"outputId":"76edb5ea-178c-4d0c-a29f-c901891f814c"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1/10] Loss: 1315.7945\n","[Epoch 2/10] Loss: 914.5612\n","[Epoch 3/10] Loss: 868.0090\n","[Epoch 4/10] Loss: 831.2142\n","[Epoch 5/10] Loss: 813.3644\n","[Epoch 6/10] Loss: 795.4296\n","[Epoch 7/10] Loss: 798.7734\n","[Epoch 8/10] Loss: 776.3153\n","[Epoch 9/10] Loss: 757.7644\n","[Epoch 10/10] Loss: 777.4769\n"]}]},{"cell_type":"code","source":["#compute SNR, PESQ\n","\n","def compute_snr(clean, noisy):\n","  noise = noisy - clean\n","  snr = 10 * np.log10(np.sum(clean ** 2) / np.sum(noise ** 2) + 1e-10)\n","  return snr\n","\n","def compute_pesq(ref_path, deg_path):\n","  sr_ref, ref = wavfile.read(ref_path)\n","  sr_deg, deg = wavfile.read(deg_path)\n","\n","  assert sr_ref == sr_deg\n","  ref = ref.astype(np.float32)\n","  deg = deg.astype(np.float32)\n","\n","  try:\n","      score = pesq(sr_ref, ref, deg, 'wb')  # Wideband mode\n","      return score\n","  except Exception as e:\n","      print(\"PESQ error:\", e)\n","      return -1.0"],"metadata":{"id":"wAOWiFige2OS","executionInfo":{"status":"ok","timestamp":1744997486353,"user_tz":-330,"elapsed":38,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["def denoise_audio_file(model_path, noisy_path, output_path, sr=16000, n_mfcc=40, seq_len=256):  # Added seq_len\n","    # Load model\n","    model = CNNDenoiser()\n","    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))  # Explicitly specify device\n","    model.eval()\n","\n","    # Load audio\n","    noisy, _ = librosa.load(noisy_path, sr=sr)\n","\n","    # Extract MFCC with padding/truncation\n","    noisy_mfcc = librosa.feature.mfcc(y=noisy, sr=sr, n_mfcc=n_mfcc)\n","\n","    # Pad or truncate to the fixed sequence length\n","    if noisy_mfcc.shape[1] < seq_len:\n","        noisy_mfcc = np.pad(noisy_mfcc, ((0, 0), (0, seq_len - noisy_mfcc.shape[1])), mode='constant')\n","    else:\n","        noisy_mfcc = noisy_mfcc[:, :seq_len]\n","\n","    noisy_tensor = torch.tensor(noisy_mfcc).unsqueeze(0).unsqueeze(0).float()\n","\n","    # Predict clean MFCC\n","    with torch.no_grad():\n","        clean_tensor = model(noisy_tensor)\n","    clean_mfcc = clean_tensor.squeeze().numpy()\n","\n","    # Convert MFCC to waveform\n","    clean_audio = librosa.feature.inverse.mfcc_to_audio(clean_mfcc, sr=sr)\n","\n","    # Ensure clean_audio and noisy_audio have the same length\n","    min_len = min(len(clean_audio), len(noisy))\n","    clean_audio = clean_audio[:min_len]\n","    noisy = noisy[:min_len]\n","\n","    # Save result\n","    sf.write(output_path, clean_audio, sr)\n","    print(f\"[âœ“] Denoised audio saved to: {output_path}\")\n","\n","    return clean_audio, noisy, sr\n","\n","if __name__ == \"__main__\":\n","    clean_audio, noisy_audio, sr = denoise_audio_file(\n","        model_path=\"cnn_denoiser.pth\",\n","        noisy_path=os.path.join('/content/drive/MyDrive/DNS/', 'input_noisy.wav'),\n","        output_path=os.path.join('/content/drive/MyDrive/DNS/', 'output_clear.wav')\n","    )\n","\n","    # Evaluate\n","    snr = compute_snr(clean_audio, noisy_audio)\n","    pesq = compute_pesq(os.path.join('/content/drive/MyDrive/DNS/', 'input_noisy.wav'), os.path.join('/content/drive/MyDrive/DNS/', 'output_clear.wav'))\n","\n","    print(f\"ðŸ”Š SNR: {snr:.2f} dB\")\n","    print(f\"ðŸ—£ï¸ PESQ: {pesq:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxaXUj0g1FDg","executionInfo":{"status":"ok","timestamp":1744997488798,"user_tz":-330,"elapsed":2455,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}},"outputId":"0f3e7e7e-dc2d-4774-d507-303ef0718b9b"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["[âœ“] Denoised audio saved to: /content/drive/MyDrive/DNS/output_clear.wav\n","ðŸ”Š SNR: -30.79 dB\n","ðŸ—£ï¸ PESQ: 1.67\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-0pzE0PE2TSM","executionInfo":{"status":"ok","timestamp":1744997488867,"user_tz":-330,"elapsed":57,"user":{"displayName":"hemanth kumar","userId":"06208238632572201291"}}},"execution_count":131,"outputs":[]}]}