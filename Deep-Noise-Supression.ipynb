{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HpeQ3kIcyj",
        "outputId": "ccbfe6a4-9d6d-4526-9d88-0f1971b5a84e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# Check for the availability of GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchaudio librosa soundfile numpy pesq sounddevice scipy"
      ],
      "metadata": {
        "id": "TLq40bm5lcFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #!pip install pesq"
      ],
      "metadata": {
        "id": "gKHAWEF1e_Rm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import random\n",
        "from glob import glob\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pesq import pesq\n",
        "from scipy.io import wavfile\n",
        "print(\"Successfully imported these packages\")"
      ],
      "metadata": {
        "id": "lgS-1vlBXGyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b717b1c3-c0ce-4642-c35c-d6dffb0ec288"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported these packages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"drive mounting initialized\")\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"drive mounting completed\")\n",
        "except:\n",
        "  print(\"Error while mounting the google drive\")"
      ],
      "metadata": {
        "id": "zsXXnUXeJHc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3588cb42-732a-42ad-c640-ff97bb15f9a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive mounting initialized\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive mounted successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Audio folders mounting initialized\")\n",
        "try:\n",
        "  clips_path = os.path.join('/content/drive/MyDrive/DNS', 'clips')\n",
        "  noise_path = os.path.join('/content/drive/MyDrive/DNS', 'noise')\n",
        "  mixed_path = os.path.join('/content/drive/MyDrive/DNS', 'mixed')\n",
        "  print(\"Successfully mounted the drive folders\")\n",
        "except:\n",
        "  print(\"Error while mounting the drive folders\")"
      ],
      "metadata": {
        "id": "NCgHKzJAlEdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe36073-9d63-49ce-da9a-fb147b3a8c9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio folders mounting initialized\n",
            "Successfully mounted the drive folders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"audio files extraction initialized\")\n",
        "try:\n",
        "  clean_files = [os.path.join(clips_path,f) for f in os.listdir(clips_path) if os.path.isfile(os.path.join(clips_path, f))]\n",
        "  clean_files.sort()\n",
        "  noisy_files = [os.path.join(noise_path,f) for f in os.listdir(noise_path) if os.path.isfile(os.path.join(noise_path, f))]\n",
        "  noisy_files.sort()\n",
        "  print(\"audio files extracted successfully\")\n",
        "except:\n",
        "  print(\"Error while extracting the audio files\")\n",
        "\n",
        "print(f\"clean files: {len(clean_files)}, Noisy files: {len(noisy_files)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMB84-uTmv2c",
        "outputId": "98d0d08a-450b-4397-8534-bc8b72e41381"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio files extraction initialized\n",
            "audio files extracted successfully\n",
            "clean files: 1164, Noisy files: 915.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute SNR\n",
        "def compute_snr(clean, noisy):\n",
        "  noise = noisy - clean\n",
        "  snr = 10 * np.log10(np.sum(clean ** 2) / np.sum(noise ** 2) + 1e-10)\n",
        "  return snr\n",
        "\n",
        "#compute PESQ\n",
        "def compute_pesq(ref_path, deg_path):\n",
        "  sr_ref, ref = wavfile.read(ref_path)\n",
        "  sr_deg, deg = wavfile.read(deg_path)\n",
        "\n",
        "  assert sr_ref == sr_deg\n",
        "  ref = ref.astype(np.float32)\n",
        "  deg = deg.astype(np.float32)\n",
        "\n",
        "  try:\n",
        "      score = pesq(sr_ref, ref, deg, 'wb')  # Wideband mode\n",
        "      return score\n",
        "  except Exception as e:\n",
        "      print(\"PESQ error:\", e)\n",
        "      return -1.0"
      ],
      "metadata": {
        "id": "wAOWiFige2OS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre process the data, combining clear_voice and noise for training\n",
        "def load_audio(file_path, sr=16000):\n",
        "  try:\n",
        "    audio, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "    return audio\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading audio file {file_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "def normalize_audio(y):\n",
        "  if y is None or len(y) == 0:\n",
        "    return y\n",
        "  return y / np.max(np.abs(y))\n",
        "\n",
        "def mix_audio(speech, noise, snr_db):\n",
        "  \"\"\"\n",
        "  Mixes speech with noise at given SNR (Signal-to-Noise Ratio)\n",
        "  \"\"\"\n",
        "  if speech is None or noise is None:\n",
        "    return None\n",
        "  speech_power = np.mean(speech ** 2)\n",
        "  noise_power = np.mean(noise ** 2)\n",
        "\n",
        "  # Avoid division by zero\n",
        "  if noise_power == 0:\n",
        "    noise_power = 1e-10\n",
        "\n",
        "  target_noise_power = speech_power / (10 ** (snr_db / 10))\n",
        "  noise = noise * np.sqrt(target_noise_power / noise_power)\n",
        "  mixed = speech + noise\n",
        "  return normalize_audio(mixed)\n",
        "\n",
        "def extract_mfcc(y, sr=16000, n_mfcc=40):\n",
        "  if y is None:\n",
        "    return None\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "  return mfcc.T\n",
        "\n",
        "def process_pair(speech_path, noise_path, mixed_dir, snr_db=5):\n",
        "  speech = load_audio(speech_path)\n",
        "  noise = load_audio(noise_path)\n",
        "\n",
        "  if speech is None or noise is None:\n",
        "    print(f\"Skipping pair due to audio loading error: {speech_path}, {noise_path}\")\n",
        "    return None, None\n",
        "\n",
        "  # Trim noise to speech length or pad speech with silence\n",
        "  if len(noise) < len(speech):\n",
        "      noise = np.tile(noise, int(np.ceil(len(speech) / len(noise))))\n",
        "  elif len(noise) > len(speech):\n",
        "      speech = np.pad(speech, (0, len(noise) - len(speech)), 'constant')\n",
        "\n",
        "  noise = noise[:len(speech)]\n",
        "  mixed = mix_audio(speech, noise, snr_db)\n",
        "\n",
        "  base_name = os.path.basename(speech_path).replace('.mp3', '.wav')\n",
        "  try:\n",
        "      sf.write(os.path.join(mixed_dir, f'clean_{base_name}'), speech, 16000)\n",
        "      sf.write(os.path.join(mixed_dir, f'noisy_{base_name}'), mixed, 16000)\n",
        "  except Exception as e:\n",
        "      print(f\"Error writing audio files: {e}\")\n",
        "      return None, None\n",
        "\n",
        "  return speech, mixed\n",
        "\n",
        "def preprocess_dataset(speech_folder, noise_folder, mixed_dir, sample_count=1000):\n",
        "  speech_files = glob(os.path.join(speech_folder, '*.mp3'))\n",
        "  noise_files = glob(os.path.join(noise_folder, '**/*.wav'), recursive=True)\n",
        "\n",
        "  os.makedirs(mixed_dir, exist_ok=True)\n",
        "\n",
        "  for i in range(sample_count):\n",
        "      if not speech_files or not noise_files:\n",
        "          print(\"No speech or noise files found. Exiting.\")\n",
        "          break\n",
        "\n",
        "      s_path = random.choice(speech_files)\n",
        "      n_path = random.choice(noise_files)\n",
        "      process_pair(s_path, n_path, mixed_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  preprocess_dataset(\n",
        "      speech_folder = clips_path,\n",
        "      noise_folder = noise_path,\n",
        "      mixed_dir = mixed_path,\n",
        "      sample_count = len(clean_files)\n",
        "  )"
      ],
      "metadata": {
        "id": "bD7QXPjmXcs9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, mixed_dir, sr=16000, n_mfcc=40, seq_len=256):\n",
        "        self.mixed_dir = mixed_dir\n",
        "        self.sr = sr\n",
        "        self.n_mfcc = n_mfcc\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # Get all mixed files paths\n",
        "        self.noisy_files = glob(os.path.join(self.mixed_dir, 'noisy_*.wav'))\n",
        "\n",
        "        # Create corresponding clean file paths\n",
        "        self.clean_files = [f.replace('noisy_', 'clean_') for f in self.noisy_files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_files)\n",
        "\n",
        "    def _fix_length(self, mfcc):\n",
        "            if mfcc.shape[1] < self.seq_len:\n",
        "                pad_width = self.seq_len - mfcc.shape[1]\n",
        "                mfcc = np.pad(mfcc, ((0,0), (0, pad_width)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:, :self.seq_len]\n",
        "            return mfcc\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            clean_path = self.clean_files[idx]\n",
        "            noisy_path = self.noisy_files[idx]\n",
        "\n",
        "            clean, _ = librosa.load(clean_path, sr=self.sr)\n",
        "            noisy, _ = librosa.load(noisy_path, sr=self.sr)\n",
        "\n",
        "\n",
        "            clean_mfcc = librosa.feature.mfcc(y=clean, sr=self.sr, n_mfcc=self.n_mfcc)\n",
        "            noisy_mfcc = librosa.feature.mfcc(y=noisy, sr=self.sr, n_mfcc=self.n_mfcc)\n",
        "\n",
        "            # Pad/trim to seq_len\n",
        "            clean_mfcc = self._fix_length(clean_mfcc)\n",
        "            noisy_mfcc = self._fix_length(noisy_mfcc)\n",
        "\n",
        "            return torch.tensor(noisy_mfcc).unsqueeze(0).float(), torch.tensor(clean_mfcc).unsqueeze(0).float()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item {idx}: {e}\")\n",
        "            # Return empty tensors with the expected shape in case of error\n",
        "            return torch.empty(1, self.n_mfcc, self.seq_len), torch.empty(1, self.n_mfcc, self.seq_len)\n"
      ],
      "metadata": {
        "id": "holrL1PjmE-k"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CNNDenoiser(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNDenoiser, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "IxUOt5W5pZ90"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Config ---\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 16\n",
        "DATA_DIR = mixed_path  # Assuming output_path is defined elsewhere\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Dataset & Loader ---\n",
        "dataset = AudioDataset(mixed_dir = mixed_path)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "# --- Model, Loss, Optimizer ---\n",
        "model = CNNDenoiser().to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# --- Training Loop ---\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    # model.train()\n",
        "    for i, (noisy, clean) in enumerate(loader):\n",
        "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(noisy)\n",
        "\n",
        "        # Fix shape mismatch\n",
        "        min_freq_dim = min(output.shape[2], clean.shape[2])  # freq/MFCC dimension\n",
        "        min_time_dim = min(output.shape[3], clean.shape[3])  # time dimension\n",
        "\n",
        "        output = output[:, :, :min_freq_dim, :min_time_dim]\n",
        "        clean = clean[:, :, :min_freq_dim, :min_time_dim]\n",
        "\n",
        "        loss = criterion(output, clean)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"[Epoch {epoch + 1}/{EPOCHS}] Loss: {total_loss / (i + 1):.4f}\")  # Average loss per batch\n",
        "\n",
        "# --- Save the model ---\n",
        "torch.save(model.state_dict(), \"cnn_denoiser.pth\")\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/DNS/cnn_denoiser.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap-h_D_rdj-7",
        "outputId": "10aa340f-eb0e-44ca-da92-f53761c89cce"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/25] Loss: 4899.2551\n",
            "[Epoch 2/25] Loss: 4448.2159\n",
            "[Epoch 3/25] Loss: 4000.8782\n",
            "[Epoch 4/25] Loss: 3537.1505\n",
            "[Epoch 5/25] Loss: 3078.5946\n",
            "[Epoch 6/25] Loss: 2621.6958\n",
            "[Epoch 7/25] Loss: 2199.0314\n",
            "[Epoch 8/25] Loss: 1817.1871\n",
            "[Epoch 9/25] Loss: 1456.2367\n",
            "[Epoch 10/25] Loss: 1165.9141\n",
            "[Epoch 11/25] Loss: 909.4071\n",
            "[Epoch 12/25] Loss: 711.2696\n",
            "[Epoch 13/25] Loss: 551.0692\n",
            "[Epoch 14/25] Loss: 437.7946\n",
            "[Epoch 15/25] Loss: 354.1339\n",
            "[Epoch 16/25] Loss: 288.9331\n",
            "[Epoch 17/25] Loss: 247.1199\n",
            "[Epoch 18/25] Loss: 223.1611\n",
            "[Epoch 19/25] Loss: 202.4805\n",
            "[Epoch 20/25] Loss: 191.4071\n",
            "[Epoch 21/25] Loss: 174.9049\n",
            "[Epoch 22/25] Loss: 164.9182\n",
            "[Epoch 23/25] Loss: 175.0644\n",
            "[Epoch 24/25] Loss: 160.0099\n",
            "[Epoch 25/25] Loss: 151.3413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_audio_file(model_path, noisy_path, output_path, sr=16000, n_mfcc=40, seq_len=256):  # Added seq_len\n",
        "    # Load model\n",
        "    model = CNNDenoiser()\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))  # Explicitly specify device\n",
        "    model.eval()\n",
        "\n",
        "    # Load audio\n",
        "    noisy, _ = librosa.load(noisy_path, sr=sr)\n",
        "\n",
        "    # Extract MFCC with padding/truncation\n",
        "    noisy_mfcc = librosa.feature.mfcc(y=noisy, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    # Pad or truncate to the fixed sequence length\n",
        "    if noisy_mfcc.shape[1] < seq_len:\n",
        "        noisy_mfcc = np.pad(noisy_mfcc, ((0, 0), (0, seq_len - noisy_mfcc.shape[1])), mode='constant')\n",
        "    else:\n",
        "        noisy_mfcc = noisy_mfcc[:, :seq_len]\n",
        "\n",
        "    noisy_tensor = torch.tensor(noisy_mfcc).unsqueeze(0).unsqueeze(0).float()\n",
        "\n",
        "    # Predict clean MFCC\n",
        "    with torch.no_grad():\n",
        "        clean_tensor = model(noisy_tensor)\n",
        "    clean_mfcc = clean_tensor.squeeze().numpy()\n",
        "\n",
        "    # Convert MFCC to waveform\n",
        "    clean_audio = librosa.feature.inverse.mfcc_to_audio(clean_mfcc, sr=sr)\n",
        "\n",
        "    # Save result\n",
        "    sf.write(output_path, clean_audio, sr)\n",
        "    print(f\"[✓] Denoised audio saved to: {output_path}\")\n",
        "\n",
        "    # Ensure clean_audio and noisy_audio have the same length\n",
        "    min_len = min(len(clean_audio), len(noisy))\n",
        "    clean_audio = clean_audio[:min_len]\n",
        "    noisy = noisy[:min_len]\n",
        "\n",
        "    return clean_audio, noisy, sr\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clean_audio, noisy_audio, sr = denoise_audio_file(\n",
        "        model_path=\"cnn_denoiser.pth\",\n",
        "        noisy_path=os.path.join('/content/drive/MyDrive/DNS/', 'input_noisy.wav'),\n",
        "        output_path=os.path.join('/content/drive/MyDrive/DNS/', 'output_clear.wav')\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    snr = compute_snr(clean_audio, noisy_audio)\n",
        "    pesq = compute_pesq(os.path.join('/content/drive/MyDrive/DNS/', 'input_noisy.wav'), os.path.join('/content/drive/MyDrive/DNS/', 'output_clear.wav'))\n",
        "\n",
        "    print(f\"🔊 SNR: {snr:.2f} dB\")\n",
        "    print(f\"🗣️ PESQ: {pesq:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxaXUj0g1FDg",
        "outputId": "4040e3f5-9648-44f1-aeec-c4582090c554"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Denoised audio saved to: /content/drive/MyDrive/DNS/output_clear.wav\n",
            "PESQ error: 'float' object is not callable\n",
            "🔊 SNR: -13.65 dB\n",
            "🗣️ PESQ: -1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0pzE0PE2TSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}